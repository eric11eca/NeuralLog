{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-03-13 00:04:47 INFO: Loading these models for language: en (English):\n",
      "========================================\n",
      "| Processor | Package                  |\n",
      "----------------------------------------\n",
      "| tokenize  | ../model/e...ize/gum.pt  |\n",
      "| pos       | ../model/en/pos/ewt.pt   |\n",
      "| lemma     | ../model/en/lemma/gum.pt |\n",
      "| depparse  | ../model/e...rse/gum.pt  |\n",
      "========================================\n",
      "\n",
      "2021-03-13 00:04:47 INFO: Use device: gpu\n",
      "2021-03-13 00:04:47 INFO: Loading: tokenize\n",
      "2021-03-13 00:04:48 INFO: Loading: pos\n",
      "2021-03-13 00:04:49 INFO: Loading: lemma\n",
      "2021-03-13 00:04:49 INFO: Loading: depparse\n",
      "2021-03-13 00:04:49 INFO: Done loading processors!\n",
      "2021-03-13 00:04:49 INFO: Loading these models for language: en (English):\n",
      "=======================================\n",
      "| Processor | Package                 |\n",
      "---------------------------------------\n",
      "| tokenize  | ../model/e...ize/gum.pt |\n",
      "=======================================\n",
      "\n",
      "2021-03-13 00:04:49 INFO: Use device: cpu\n",
      "2021-03-13 00:04:49 INFO: Loading: tokenize\n",
      "2021-03-13 00:04:49 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "from Udep2Mono.util import btree2list\n",
    "from Udep2Mono.dependency_parse import tokenizer\n",
    "from Udep2Mono.dependency_parse import dependency_parse\n",
    "from Udep2Mono.binarization import BinaryDependencyTree\n",
    "from Udep2Mono.polarization import PolarizationPipeline\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "sentenceTransformer = SentenceTransformer(\"roberta-large-nli-stsb-mean-tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.tree import Tree\n",
    "from nltk.draw import TreeWidget\n",
    "from nltk.draw.util import CanvasFrame\n",
    "from IPython.display import Image, display\n",
    "\n",
    "def jupyter_draw_nltk_tree(tree):\n",
    "    cf = CanvasFrame()\n",
    "    tc = TreeWidget(cf.canvas(), tree)\n",
    "    tc['node_font'] = 'arial 14 bold'\n",
    "    tc['leaf_font'] = 'arial 14'\n",
    "    tc['node_color'] = '#005990'\n",
    "    tc['leaf_color'] = '#3F8F57'\n",
    "    tc['line_color'] = '#175252'\n",
    "    cf.add_widget(tc, 20, 20)\n",
    "    os.system('rm -rf ../data/tree.png')\n",
    "    os.system('rm -rf ../data/tree.ps')\n",
    "    cf.print_to_file('../data/tree.ps')\n",
    "    cf.destroy()\n",
    "    os.system('convert ../data/tree.ps ../data/tree.png')\n",
    "    display(Image(filename='../data/tree.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_sts(seq1s, seq2s):\n",
    "    embeddings1 = sentenceTransformer.encode(seq1s, convert_to_tensor=True)\n",
    "    embeddings2 = sentenceTransformer.encode(seq2s, convert_to_tensor=True)\n",
    "    cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "    return cosine_scores[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at textattack/roberta-base-MRPC were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "roberta_MRPC = \"textattack/roberta-base-MRPC\"\n",
    "bert_MRPC = \"bert-base-cased-finetuned-mrpc\"\n",
    "\n",
    "paraphraseTokenizer = AutoTokenizer.from_pretrained(roberta_MRPC)  \n",
    "paraphraseModel = AutoModelForSequenceClassification.from_pretrained(roberta_MRPC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chunker import Chunker\n",
    "\n",
    "class SyntacticVariator:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.chunker = Chunker()\n",
    "        self.paraphraseTokenizer = paraphraseTokenizer\n",
    "        self.paraphraseModel = paraphraseModel\n",
    "\n",
    "    def chunking(self, tree):\n",
    "        return self.chunker.get_chunks_byDepTree(tree)\n",
    "\n",
    "    def build_pairs(self, chunks1, chunks2):\n",
    "        chunk_pairs = []\n",
    "        for chunk1 in chunks1:\n",
    "            for chunk2 in chunks2:\n",
    "                if len(set(chunk1.split(' ')).intersection(chunk2.split(' '))) > 0:\n",
    "                     chunk_pairs.append((chunk1, chunk2))\n",
    "\n",
    "        return chunk_pairs\n",
    "\n",
    "    def inference_mrpc(self, seq1, seq2):\n",
    "        paraphrase = paraphraseTokenizer.encode_plus(\n",
    "            seq1, seq2, return_tensors=\"pt\")\n",
    "        logits = paraphraseModel(**paraphrase)[0]\n",
    "        paraphrase_results = torch.softmax(logits, dim=1).tolist()[0]\n",
    "        return paraphrase_results[1]\n",
    "\n",
    "    def phrase_alignment(self, chunk_pairs):\n",
    "        alignments = []\n",
    "        for pair in chunk_pairs:\n",
    "            score = self.inference_mrpc(pair[0], pair[1])\n",
    "            print(pair, score)\n",
    "            if score > 0.85:\n",
    "                alignments.append(pair)\n",
    "\n",
    "        return alignments\n",
    "\n",
    "    def variate(self, sentence, p_tree, h_tree):\n",
    "        p_chunks = self.chunking(p_tree)\n",
    "        h_chunks = self.chunking(h_tree)\n",
    "\n",
    "        chunk_pairs = self.build_pairs(p_chunks, h_chunks)\n",
    "        alignments = self.phrase_alignment(chunk_pairs)\n",
    "\n",
    "        var_sentence = copy(sentence)\n",
    "        for align in alignments:\n",
    "            var_sentence = var_sentence.replace(align[0], align[1])\n",
    "\n",
    "        return var_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('not take', 'not take') 0.9298083186149597\n('not take', 'not take any different opinion') 0.059350091964006424\n('not take criticism', 'not take') 0.5380662083625793\n('not take criticism', 'not take any different opinion') 0.2235867828130722\nTom does not take criticism well tensor(0.6538)\n"
     ]
    }
   ],
   "source": [
    "premise = \"Tom does not take criticism well\"\n",
    "hypothesis = \"Tom does not take any different opinion well\"\n",
    "\n",
    "pipeline = PolarizationPipeline()\n",
    "syntacticVariator = SyntacticVariator()\n",
    "\n",
    "h_parsed, replaced = dependency_parse(hypothesis, parser=\"stanza\")\n",
    "h_tree, _ = pipeline.run_binarization(h_parsed, hypothesis, {})\n",
    "pipeline.modify_replacement(h_tree, replaced)\n",
    "annotation = pipeline.single_polarization(premise)\n",
    "\n",
    "variate = syntacticVariator.variate(premise, annotation['polarized_tree'], h_tree)\n",
    "similarity = inference_sts([variate], [hypothesis])\n",
    "print(variate, similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pattern.en import pluralize, singularize\n",
    "from copy import copy\n",
    "import re\n",
    "import torch\n",
    "\n",
    "class PhrasalGenerator:\n",
    "    def __init__(self):\n",
    "        self.deptree = None\n",
    "        self.annotated = None\n",
    "        self.original = None\n",
    "        self.kb = {}\n",
    "        self.hypothesis = \"\"\n",
    "        self.tree_log = []\n",
    "        self.sent_log = []\n",
    "        self.stop_critarion = False\n",
    "        self.mod_at_left = [\n",
    "            \"advmod\", \"amod\", \"advmod:count\", \n",
    "            \"acl:relcl\", \"obl\", 'obl:npmod', \n",
    "            \"obl:tmod\", \"nmod\", \"nmod:npmod\", \n",
    "            \"nmod:poss\", \"nmod:tmod\", \"obl:npmod\",\n",
    "            \"acl\", \"advcl\", \"xcomp\", \"ccomp\", \n",
    "            \"appos\", 'compound:ptr']\n",
    "        self.mod_at_right = []\n",
    "        self.mod_symmetric = [\"conj\", \"compound\"]\n",
    "        \n",
    "        '''  \n",
    "            \"cop\": self.generate_inherite, \n",
    "            \"expl\": self.generate_expl,\n",
    "            \"nummod\": self.generate_nummod,\n",
    "        '''\n",
    "\n",
    "    def deptree_generate(self, tree, annotated, original):\n",
    "        self.stop_critarion = False\n",
    "        self.tree_log = []\n",
    "        self.sent_log = []\n",
    "        self.deptree = tree.copy()\n",
    "        self.original = original  \n",
    "        self.annotated = deepcopy(annotated)\n",
    "        self.sentence = original\n",
    "        self.generate(self.deptree)\n",
    "\n",
    "    def generate(self, tree):\n",
    "        if self.stop_critarion:\n",
    "            return\n",
    "        if not tree.is_tree:\n",
    "            self.generate_default(tree)\n",
    "        else:\n",
    "            generation = self.get_generation_type(tree)\n",
    "            generation(tree)\n",
    "\n",
    "    def get_generation_type(self, tree):\n",
    "        disjunction = False\n",
    "        if tree.val == \"conj\":\n",
    "            disjunction |= self.search_dependency('or', tree.left)\n",
    "            disjunction |= self.search_dependency('and', tree.left)\n",
    "        \n",
    "        left_mod = tree.left.mark == \"+\"\n",
    "        left_mod = left_mod or tree.left.mark == \"=\" or disjunction\n",
    "        left_mod = left_mod and tree.val in self.mod_at_left\n",
    "\n",
    "        right_mod = tree.right.mark == \"+\" or tree.right.mark == \"=\"\n",
    "        right_mod = right_mod or disjunction \n",
    "\n",
    "        sym_mod = tree.val in self.mod_symmetric and left_mod and right_mod\n",
    "\n",
    "        if left_mod:\n",
    "            return self.left_modifier_generate\n",
    "        elif sym_mod:\n",
    "            return self.symmetric_generate\n",
    "        else:\n",
    "            return self.generate_default\n",
    "\n",
    "    def delete_cc(self, tree):\n",
    "        if tree.val == \"cc\" and tree.left.val != \"but\":\n",
    "            self.delete_modifier(tree, tree.right)\n",
    "\n",
    "        if tree.is_tree:\n",
    "            self.delete_cc(tree.left)\n",
    "            self.delete_cc(tree.right)\n",
    "\n",
    "    def delete_modifier(self, tree, modifier):\n",
    "        tree.val = modifier.val\n",
    "        tree.mark = modifier.mark\n",
    "        tree.pos = modifier.pos\n",
    "        tree.id = modifier.id\n",
    "        \n",
    "        tree.is_tree = modifier.is_tree\n",
    "        tree.is_root = modifier.is_root\n",
    "\n",
    "        tree.left = modifier.left\n",
    "        tree.right = modifier.right\n",
    "\n",
    "        self.delete_cc(tree)\n",
    "        self.save_tree()\n",
    "\n",
    "    def delete_left_modifier(self, tree):\n",
    "        self.delete_modifier(tree, tree.right)\n",
    "\n",
    "    def delete_right_modifier(self, tree):\n",
    "        self.delete_modifier(tree, tree.left)\n",
    "\n",
    "    def rollback(self, tree, backup):\n",
    "        tree.val = backup.val\n",
    "        tree.left = deepcopy(backup.left)\n",
    "        tree.right = deepcopy(backup.right)\n",
    "        tree.mark = backup.mark\n",
    "        tree.pos = backup.pos\n",
    "        tree.id = backup.id\n",
    "        tree.is_tree = backup.is_tree\n",
    "        tree.is_root = backup.is_root\n",
    "\n",
    "    def symmetric_generate(self, tree):\n",
    "        self.right_modifier_generate(tree)\n",
    "        self.left_modifier_generate(tree)\n",
    "        self.delete_cc(tree)\n",
    "\n",
    "    def right_modifier_generate(self, tree):\n",
    "        left = tree.left\n",
    "        right = tree.right\n",
    "        backup = deepcopy(tree)\n",
    "\n",
    "        self.delete_right_modifier(tree)\n",
    "        self.save_tree()\n",
    "        self.rollback(tree, backup)    \n",
    "        \n",
    "        self.generate(tree.left)\n",
    "        self.generate(tree.right)\n",
    "\n",
    "    def left_modifier_generate(self, tree):\n",
    "        left = tree.left\n",
    "        right = tree.right\n",
    "        backup = deepcopy(tree)\n",
    "\n",
    "        self.delete_left_modifier(tree)\n",
    "        self.save_tree()\n",
    "        self.rollback(tree, backup)   \n",
    "\n",
    "        self.generate(tree.left)\n",
    "        self.generate(tree.right)\n",
    "    \n",
    "    def return_last_leaf(self, tree):\n",
    "        max_id = 0\n",
    "        max_id_l = 0\n",
    "        max_id_r = 0\n",
    "\n",
    "        if tree.id != None:\n",
    "            max_id = int(tree.id)\n",
    "    \n",
    "        if tree.left.is_tree:\n",
    "            max_id_l = self.return_last_leaf(tree.left)\n",
    "        else:\n",
    "            max_id_l = tree.left.id\n",
    "\n",
    "        if tree.right.is_tree:\n",
    "            max_id_r = self.return_last_leaf(tree.right)\n",
    "        else:\n",
    "            max_id_r = tree.right.id\n",
    "\n",
    "        return max(max_id, max(max_id_l, max_id_r))\n",
    "\n",
    "    def return_first_leaf(self, tree):\n",
    "        min_id = 100\n",
    "        min_id_l = 100\n",
    "        min_id_r = 100\n",
    "\n",
    "        if tree.id != None:\n",
    "            min_id = int(tree.id)\n",
    "    \n",
    "        if tree.left.is_tree:\n",
    "            min_id_l = self.return_last_leaf(tree.left)\n",
    "        else:\n",
    "            min_id_l = tree.left.id\n",
    "\n",
    "        if tree.right.is_tree:\n",
    "            min_id_r = self.return_last_leaf(tree.right)\n",
    "        else:\n",
    "            min_id_r = tree.right.id\n",
    "\n",
    "        return min(min_id, min(min_id_l, min_id_r))\n",
    "\n",
    "    def add_modifier_sent(self, tree, modifier, direct=0): \n",
    "        sentence = deepcopy(self.sentence)\n",
    "        if direct == 0:\n",
    "            last_leaf = self.return_first_leaf(tree)\n",
    "            sentence.insert(last_leaf-1, modifier)\n",
    "        elif direct == 1:\n",
    "            last_leaf = self.return_last_leaf(tree)\n",
    "            sentence.insert(last_leaf, modifier)        \n",
    "\n",
    "        self.remove_adjcent_duplicate(sentence)\n",
    "        sentence = ' '.join(sentence)\n",
    "        sentence = sentence.replace(\"-\", \" \")\n",
    "        sentence = sentence.replace(\" 's\", \"'s\")\n",
    "\n",
    "        if abs(len(sentence) - len(self.hypothesis)) < 15:\n",
    "            re.sub(r'((\\b\\w+\\b.{1,2}\\w+\\b)+).+\\1', r'\\1', sentence, flags = re.I)\n",
    "            sentence = sentence.strip() \n",
    "            \n",
    "            if sentence.lower() == self.hypothesis.lower():\n",
    "                self.stop_critarion = True\n",
    "                self.sent_log.append((sentence, 1.0))\n",
    "                return\n",
    "                \n",
    "            similarity = inference_sts([sentence], [self.hypothesis])\n",
    "            if similarity > 0.90:\n",
    "                self.sent_log.append((sentence, similarity))\n",
    "            if similarity > 0.97:\n",
    "                self.sent_log.append((sentence, similarity))\n",
    "                self.stop_critarion = True\n",
    "\n",
    "    def add_modifier_lexical(self, tree, modifier, head, word_id, direct=0):\n",
    "        if direct == 0:\n",
    "            generated = ' '. join([modifier, head])\n",
    "        else:\n",
    "            generated = ' '. join([head, modifier])\n",
    "        \n",
    "        sentence = deepcopy(self.sentence)\n",
    "        diff = 0\n",
    "        if word_id > len(sentence):\n",
    "            diff = word_id - len(sentence)\n",
    "\n",
    "        goal = word_id-1-diff\n",
    "        sentence[goal] = \"DEL\"\n",
    "        sentence[goal:goal] = generated.split(' ')\n",
    "\n",
    "        if abs(len(sentence) - len(self.hypothesis.split(' '))) < 7:\n",
    "            self.remove_adjcent_duplicate(sentence)\n",
    "            sentence = ' '.join(sentence)\n",
    "            sentence = sentence.replace(\"DEL \", \"\")\n",
    "            sentence = sentence.replace(\"DEL\", \"\")\n",
    "            sentence = sentence.replace(\"-\", \" \")\n",
    "            sentence = sentence.replace(\" 's\", \"'s\")\n",
    "            re.sub(r'((\\b\\w+\\b.{1,2}\\w+\\b)+).+\\1', r'\\1', sentence, flags = re.I)\n",
    "            sentence = sentence.strip()\n",
    "\n",
    "            if sentence.lower() == self.hypothesis.lower():\n",
    "                self.stop_critarion = True\n",
    "                self.sent_log.append((sentence, 1.0))\n",
    "                return\n",
    "            \n",
    "            similarity = inference_sts([sentence], [self.hypothesis])\n",
    "            if similarity > 0.9:\n",
    "                self.sent_log.append((sentence, similarity))\n",
    "            if similarity > 0.97:\n",
    "                self.sent_log.append((sentence, similarity))\n",
    "                self.stop_critarion = True\n",
    "\n",
    "    def generate_default(self, tree):\n",
    "        VP_rel = {\n",
    "            \"aux\":1, \n",
    "            \"obj\":1, \n",
    "            \"obl\":1, \n",
    "            \"xcomp\":1, \n",
    "            \"ccomp\":1,\n",
    "            \"aux:pass\":1, \n",
    "            \"obl:tmod\":1, \n",
    "            \"obl:npmod\":1\n",
    "        }\n",
    "\n",
    "        VP_mod = {\n",
    "            \"advcl\":1, \n",
    "            \"xcomp\":1, \n",
    "            \"ccomp\":1,\n",
    "            \"obj\":1, \n",
    "            \"advmod\":1, \n",
    "            \"obl\":1, \n",
    "            \"obl:tmod\":1,\n",
    "            \"obl:nmod\":1, \n",
    "            \"parataxis\":1, \n",
    "            \"conj\":1\n",
    "        }\n",
    "\n",
    "        NP_rel = {\n",
    "            \"amod\":1,\n",
    "            \"compound\":1,\n",
    "            \"det\":1,\n",
    "            \"mark\":1,\n",
    "            \"nmod:poss\":1,\n",
    "            \"flat\":1,\n",
    "            \"acl:relcl\":1,\n",
    "            \"acl\":1,\n",
    "            \"nmod\":1\n",
    "        }\n",
    "\n",
    "        NP_mod = {\n",
    "            \"amod\":1,\n",
    "            \"compound\":1,\n",
    "            \"det\":1,\n",
    "            \"mark\":1,\n",
    "            \"nmod:poss\":1,\n",
    "            \"flat\":1,\n",
    "        }\n",
    "\n",
    "        if tree.pos is not None:\n",
    "            if (\"NN\" in tree.pos or \"JJ\" in tree.pos) and tree.mark == \"-\":\n",
    "                for rel in [\"amod\", \"compound\", \"det\", \"mark\", \"nmod:poss\", \"flat\", \"conj\", \"nummod\"]:\n",
    "                    if rel in self.kb:\n",
    "                        for phrase in self.kb[rel]:\n",
    "                            if phrase['head'] == tree.val:\n",
    "                                self.add_modifier_lexical(tree, phrase['mod'], tree.val, tree.id)\n",
    "                for rel in [\"amod\", \"acl:relcl\", \"compound\", \"acl\", \"nmod\"]:\n",
    "                    if rel in self.kb:\n",
    "                        for phrase in self.kb[rel]:\n",
    "                            if phrase['head'] == tree.val:\n",
    "                                self.add_modifier_lexical(tree, phrase['mod'], tree.val, tree.id, 1)\n",
    "                \n",
    "            elif \"VB\" in tree.pos and tree.mark == \"-\":\n",
    "                for rel in [\"advmod\"]:\n",
    "                    if rel in self.kb:\n",
    "                        for phrase in self.kb[rel]:\n",
    "                            self.add_modifier_lexical(tree, phrase['mod'], tree.val, tree.id)\n",
    "                            self.add_modifier_lexical(tree, phrase['mod'], tree.val, tree.id, 1)\n",
    "\n",
    "        elif VP_rel.get(tree.val, 0) and tree.mark == \"-\":\n",
    "            for rel in VP_mod:\n",
    "                if rel in self.kb:\n",
    "                    for phrase in self.kb[rel]:\n",
    "                        self.add_modifier_sent(tree, phrase['mod'], direct=1)\n",
    "\n",
    "        elif NP_rel.get(tree.val, 0) and tree.mark == \"-\":\n",
    "            for rel in NP_mod:\n",
    "                if rel in self.kb:\n",
    "                    for phrase in self.kb[rel]:\n",
    "                        self.add_modifier_sent(tree, phrase['mod'], direct=0)\n",
    "\n",
    "        if tree.is_tree:\n",
    "            self.generate(tree.left)\n",
    "            self.generate(tree.right)  \n",
    "\n",
    "    def save_tree(self):\n",
    "        leaves = self.deptree.sorted_leaves().popkeys()\n",
    "        sentence = ' '.join([x[0] for x in leaves])\n",
    "\n",
    "        if sentence.lower() == self.hypothesis.lower():\n",
    "            self.tree_log = []\n",
    "            self.stop_critarion = True\n",
    "            self.tree_log.append((self.deptree.copy(), sentence, 1.0))\n",
    "            return\n",
    "        \n",
    "        similarity = inference_sts([sentence], [self.hypothesis])\n",
    "        if similarity > 0.9:\n",
    "            self.tree_log.append((self.deptree.copy(), sentence, similarity))\n",
    "        if similarity > 0.97:\n",
    "            self.tree_log = []\n",
    "            self.tree_log.append((self.deptree.copy(), sentence, similarity))\n",
    "            self.stop_critarion = True\n",
    "    \n",
    "    def remove_adjcent_duplicate(self, string):\n",
    "        to_remove = -1\n",
    "        for i in range(len(string)-1):\n",
    "            if string[i] == string[i+1]:\n",
    "                to_remove = i\n",
    "        if to_remove > -1:\n",
    "            del string[to_remove]\n",
    "\n",
    "    def search_dependency(self, deprel, tree):\n",
    "        if tree.val == deprel:\n",
    "            return True\n",
    "        else:\n",
    "            right = tree.right\n",
    "            left = tree.left\n",
    "\n",
    "            left_found = False\n",
    "            right_found = False\n",
    "\n",
    "            if right is not None:\n",
    "                right_found = self.search_dependency(deprel, right)\n",
    "\n",
    "            if left is not None:\n",
    "                left_found = self.search_dependency(deprel, left)\n",
    "\n",
    "            return left_found or right_found\n",
    "    \n",
    "    def Diff(self, li1, li2):\n",
    "        return (list(list(set(li1)-set(li2)) + list(set(li2)-set(li1))))    \n",
    "    \n",
    "    def preprocess(self, sentence):\n",
    "        preprocessed = sentence.replace(\".\", \"\").replace(\"!\", \"\").replace(\"?\", \"\")\n",
    "        preprocessed = preprocessed.replace(\"can't\", \"can not\")\n",
    "        preprocessed = preprocessed.replace(\"couldn't\", \"could not\")\n",
    "        preprocessed = preprocessed.replace(\"don't\", \"do not\")\n",
    "        preprocessed = preprocessed.replace(\"doesn't\", \"does not\")\n",
    "        preprocessed = preprocessed.replace(\"isn't\", \"is not\")\n",
    "        preprocessed = preprocessed.replace(\"won't\", \"will not\")\n",
    "        preprocessed = preprocessed.replace(\"wasn't\", \"was not\")\n",
    "        preprocessed = preprocessed.replace(\"weren't\", \"were not\")\n",
    "        preprocessed = preprocessed.replace(\"didn't\", \"did not\")\n",
    "        preprocessed = preprocessed.replace(\"aren't\", \"are not\")\n",
    "        preprocessed = preprocessed.replace(\"it's\", \"it is\")\n",
    "        preprocessed = preprocessed.replace(\"wouldn't\", \"would not\")\n",
    "        preprocessed = preprocessed.replace(\"There's\", \"There is\")\n",
    "        return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "modifier_relation = {\n",
    "    \"NN\": [\"amod\", \"nmod\", \"acl:relcl\", \"fixed\", \"compound\", \"det\", \"nmod:poss\", \"conj\", \"nummod\"],\n",
    "    \"VB\": [\"advmod\", \"acl\", \"obl\", \"xcomp\", \"advcl\", \"obl:tmod\", \"parataxis\", \"obj\",\"ccomp\"]\n",
    "}\n",
    "\n",
    "def down_right(tree):\n",
    "    if(tree.right == None):\n",
    "        return tree\n",
    "    return down_right(tree.right)\n",
    "\n",
    "def down_left(tree):\n",
    "    if(tree.left == None):\n",
    "        return tree\n",
    "    return down_left(tree.left)\n",
    "\n",
    "def collect_modifiers(tree, sent_set, mod_type=\"NN\"):\n",
    "    leaves = []\n",
    "    if tree.is_tree:\n",
    "        if tree.val in [\"mark\", \"case\", \"compound\", \"flat\"]:\n",
    "            leaves.append(\n",
    "                (list(tree.right.sorted_leaves().popkeys()),\n",
    "                down_right(tree.left).val)\n",
    "            )\n",
    "        if tree.val in modifier_relation[mod_type]:\n",
    "            leaves.append(\n",
    "                (list(tree.left.sorted_leaves().popkeys()),\n",
    "                down_right(tree.right).val)\n",
    "            )\n",
    "\n",
    "        for leave in leaves:\n",
    "            if len(leave) > 0 and len(leave) < 10:\n",
    "                head = leave[1]\n",
    "                modifier = ' '.join([x[0] for x in leave[0]])\n",
    "                if tree.val in sent_set:\n",
    "                    sent_set[tree.val].append({'head': head,'mod': modifier})\n",
    "                else:\n",
    "                    sent_set[tree.val] = [{'head': head,'mod': modifier}]\n",
    "        \n",
    "        collect_modifiers(tree.left, sent_set, mod_type)\n",
    "        collect_modifiers(tree.right, sent_set, mod_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MED_upward = []\n",
    "MED_upward_hypo = []\n",
    "MED_downward = []\n",
    "MED_downward_hypo = []\n",
    "\n",
    "with open(\"../data/MED/upward.txt\") as upward_med:\n",
    "    lines = upward_med.readlines()\n",
    "    for i in range(len(lines) // 4):\n",
    "        MED_upward.append(lines[i*4+1])\n",
    "        MED_upward_hypo.append(lines[i*4+2])\n",
    "\n",
    "with open(\"../data/MED/downward.txt\") as donward_med:\n",
    "    lines = donward_med.readlines()\n",
    "    for i in range(len(lines) // 4):\n",
    "        MED_downward.append(lines[i*4+1])\n",
    "        MED_downward_hypo.append(lines[i*4+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n====================================\n\nInit Premise: I do not want to have children\n\nHypothesis: I do not want to have four children\n{   'advmod': [{'head': 'want', 'mod': 'not'}],\n    'mark': [   {'head': 'to', 'mod': 'have four children'},\n                {'head': 'to', 'mod': 'have four children'}],\n    'nummod': [{'head': 'children', 'mod': 'four'}],\n    'obj': [{'head': 'have', 'mod': 'four children'}],\n    'xcomp': [{'head': 'want', 'mod': 'to have four children'}]}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('I do not want to have children four children', tensor(0.9622))\n('I do not want to have children four children', tensor(0.9622))\n('I do not want to have children four children', tensor(0.9622))\n('I do not want to have four children', 1.0)\nTrue\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "up = [\"I do not want to have children\"]\n",
    "up_h = [\"I do not want to have four children\"]\n",
    "\n",
    "annotations = []\n",
    "phrasalGenerator = PhrasalGenerator()\n",
    "pipeline = PolarizationPipeline(verbose=0)\n",
    "for i in range(len(up)):\n",
    "    premise = up[i]\n",
    "    hypothesis = up_h[i]\n",
    "    premise = phrasalGenerator.preprocess(premise)\n",
    "    hypothesis = phrasalGenerator.preprocess(hypothesis)\n",
    "\n",
    "    tokenized = tokenizer(premise).sentences[0].words\n",
    "    tokens = [tok.text for tok in tokenized]\n",
    "\n",
    "    print(\"\\n====================================\")\n",
    "    print(\"\\nInit Premise: \" + premise)\n",
    "    print(\"\\nHypothesis: \" + hypothesis)\n",
    "\n",
    "    h_parsed, replaced = dependency_parse(hypothesis, parser=\"stanza\")\n",
    "    h_tree, _ = pipeline.run_binarization(h_parsed, hypothesis, {})\n",
    "    pipeline.modify_replacement(h_tree, replaced)\n",
    "    phrases = {} \n",
    "    collect_modifiers(h_tree, phrases, mod_type=\"NN\")\n",
    "    collect_modifiers(h_tree, phrases, mod_type=\"VB\")\n",
    "    annotation = pipeline.single_polarization(premise)\n",
    "    \n",
    "    phrasalGenerator.kb = phrases\n",
    "    phrasalGenerator.hypothesis = hypothesis.replace(',', '')\n",
    "    pp.pprint(phrasalGenerator.kb)\n",
    "    \n",
    "    polarized = pipeline.postprocess(annotation['polarized_tree'], {})\n",
    "    btreeViz = Tree.fromstring(polarized.replace('[', '(').replace(']', ')'))\n",
    "    jupyter_draw_nltk_tree(btreeViz) \n",
    "\n",
    "    polarized = pipeline.postprocess(h_tree, {})\n",
    "    btreeViz = Tree.fromstring(polarized.replace('[', '(').replace(']', ')'))\n",
    "    jupyter_draw_nltk_tree(btreeViz)\n",
    "    \n",
    "    phrasalGenerator.deptree_generate(\n",
    "        annotation['polarized_tree'], \n",
    "        annotation['annotated'], tokens)\n",
    "\n",
    "    for gen_tree in phrasalGenerator.tree_log:\n",
    "        #leaves = gen_tree[0].sorted_leaves().popkeys()\n",
    "        #sentence = ' '.join([x[0] for x in leaves])\n",
    "        print((gen_tree[1], gen_tree[2]))\n",
    "\n",
    "    print(*phrasalGenerator.sent_log, sep=\"\\n\")\n",
    "    print(phrasalGenerator.stop_critarion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 82%| | 164/200 [01:06<00:12,  2.93it/s]('He prefers to drink coffee without sugar or milk', 'He prefers to drink coffee without sugar or milk')\n",
      "('He prefers to drink coffee without sugar or milk', 'He prefers to drink coffee without sugar or milk')\n",
      " 88%| | 177/200 [01:11<00:09,  2.46it/s]('No joker should be without a whoopee cushion', 'No joker should be without a whoopee cushion')\n",
      "('No joker should be without a whoopee cushion', 'No joker should be without a whoopee cushion')\n",
      " 96%|| 191/200 [01:16<00:03,  2.73it/s]('The villagers have done without electricity for a time', 'The villagers have done without electricity for a time')\n",
      "('The villagers have done without electricity for a time', 'The villagers have done without electricity for a time')\n",
      "100%|| 200/200 [01:19<00:00,  2.50it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "annotations = []\n",
    "with open(\"./generation_log_donward.txt\", 'w') as generate_log:\n",
    "    phrasalGenerator = PhrasalGenerator()\n",
    "    pipeline = PolarizationPipeline(verbose=0)\n",
    "    for i in tqdm(range(1200, 1400)):\n",
    "        premise = MED_downward[i].replace('\\n', '')\n",
    "        hypothesis = MED_downward_hypo[i].replace('\\n', '')\n",
    "        premise = phrasalGenerator.preprocess(premise)\n",
    "        hypothesis = phrasalGenerator.preprocess(hypothesis)\n",
    "\n",
    "        tokenized = tokenizer(premise).sentences[0].words\n",
    "        tokens = [tok.text for tok in tokenized]\n",
    "\n",
    "        try:\n",
    "            h_parsed, replaced = dependency_parse(hypothesis, parser=\"stanza\")\n",
    "            h_tree, _ = pipeline.run_binarization(h_parsed, hypothesis, {})\n",
    "        except:\n",
    "            generate_log.write(\"\\nPremise: \" + premise)\n",
    "            generate_log.write(\"\\nHypothesis: \" + hypothesis)\n",
    "            continue\n",
    "        pipeline.modify_replacement(h_tree, replaced)\n",
    "        phrases = {} \n",
    "        collect_modifiers(h_tree, phrases, mod_type=\"NN\")\n",
    "        collect_modifiers(h_tree, phrases, mod_type=\"VB\")\n",
    "\n",
    "        try:\n",
    "            annotation = pipeline.single_polarization(premise)\n",
    "        except:\n",
    "            generate_log.write(\"\\nPremise: \" + premise)\n",
    "            generate_log.write(\"\\nHypothesis: \" + hypothesis)\n",
    "            continue\n",
    "    \n",
    "        phrasalGenerator.kb = phrases\n",
    "        #print(phrasalGenerator.kb)\n",
    "        phrasalGenerator.hypothesis = hypothesis.replace(',', '')\n",
    "        \n",
    "        phrasalGenerator.deptree_generate(\n",
    "            annotation['polarized_tree'], \n",
    "            annotation['annotated'], \n",
    "            tokens)\n",
    "\n",
    "        for gen_tree in phrasalGenerator.tree_log:\n",
    "            leaves = gen_tree[0].sorted_leaves().popkeys()\n",
    "            sentence = ' '.join([x[0] for x in leaves])\n",
    "            print((sentence, gen_tree[1]))\n",
    "            \n",
    "        if not phrasalGenerator.stop_critarion:\n",
    "            generate_log.write(\"\\nID: \" + str(i))\n",
    "            generate_log.write(\"\\nPremise: \" + premise)\n",
    "            generate_log.write(\"\\nHypothesis: \" + hypothesis)\n",
    "            #print(\"\\nPremise: \" + premise)\n",
    "            #print(\"\\nHypothesis: \" + hypothesis)\n",
    "            #print(*phrasalGenerator.sent_log, sep=\"\\n\")\n",
    "            #generate_log.writelines(phrasalGenerator.sent_log)\n",
    "            generate_log.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"Some red flowers need light\", \n",
    "             \"Some red and beautiful flowers need light\",\n",
    "             \"All flowers need light and water\", \n",
    "             \"No flowers need bright or warm light\",\n",
    "             \"John can sing and dance\",\n",
    "             \"John ate an apple and finished his homework\",\n",
    "             \"John finished his homework and did not eat an apple\"]\n",
    "\n",
    "upward = [\"Some students sing to celebrate their graduation\",\n",
    "          \"An Irishman won the nobel prize for literature.\",\n",
    "          \"A big poison spider was spanning a web\", \n",
    "          \"A Californian special policeman pulled a car over and spoke to the driver\",\n",
    "          \"A woman is dancing in a cage\", \n",
    "          \"A woman is dancing beautifully in a cage\", \n",
    "          \"People are riding and paddling a raft\", \n",
    "          \"Some delegates finished the survey on time\"]\n",
    "\n",
    "sick_upward = [\"A brown dog is attacking another animal in front of the tall man in pants\",\n",
    "               \"A skilled person is riding a bicycle on one wheel\",\n",
    "               \"Two children are lying in the snow and are drawing angels\"]\n",
    "\n",
    "downward = [\"No spider was spanning a web\",\n",
    "            \"No student finished homework\",\n",
    "            \"I've never flown in an airplane\"]\n",
    "\n",
    "hypothesis = [\"No poison spider was spanning a web\", \n",
    "              \"No student at school finished homework compeletly\",\n",
    "              \"I've never flown in an airplane because i'm afraid.\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}