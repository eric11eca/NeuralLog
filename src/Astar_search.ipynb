{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "from pqdict import pqdict\n",
    "\n",
    "import torch\n",
    "#from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "#paraphraseTokenizer = AutoTokenizer.from_pretrained(\"textattack/roberta-base-MRPC\")  \n",
    "#paraphraseModel = AutoModelForSequenceClassification.from_pretrained(\"textattack/#roberta-base-MRPC\")\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "model_name = \"roberta-base-nli-stsb-mean-tokens\"\n",
    "sentenceBERT = SentenceTransformer(model_name)\n",
    "classes = [\"not paraphrase\", \"is paraphrase\"]\n",
    "\n",
    "def inference_mrpc(seq1s, seq2s):\n",
    "    for i in range(len(seq1s)):\n",
    "        paraphrase = paraphraseTokenizer.encode_plus(\n",
    "            seq1s[i], seq2s[i], return_tensors=\"pt\")\n",
    "        logits = paraphraseModel(**paraphrase)[0]\n",
    "        paraphrase_results = torch.softmax(logits, dim=1).tolist()[0]\n",
    "        print(f\"{classes[1]}: {round(paraphrase_results[1] * 100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:allennlp.common.plugins:Plugin allennlp_models could not be loaded: No module named 'transformers.models.bart'\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='downloading'), FloatProgress(value=0.0, max=54185577.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "89d9b386f39740ff9bdd783ace66b2e2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "WARNING:allennlp.common.params:error loading _jsonnet (this is expected on Windows), treating C:\\Users\\ZEMING~1\\AppData\\Local\\Temp\\tmpsv0wahn4\\config.json as plain json\n",
      "WARNING:allennlp.common.util:Spacy models 'en_core_web_sm' not found.  Downloading and installing.\n",
      "✔ Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "  0%|          | 933k/1.31G [49:37<1164:01:41, 313B/s]\n"
     ]
    }
   ],
   "source": [
    "from Udep2Mono.binarization import BinaryDependencyTree\n",
    "from Udep2Mono.polarization import PolarizationPipeline\n",
    "from Udep2Mono.util import btreeToList\n",
    "from copy import deepcopy\n",
    "\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "import allennlp_models.structured_prediction\n",
    "\n",
    "ie_extractor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/openie-model.2020.03.26.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pattern.en import pluralize, singularize\n",
    "\n",
    "def fix_info(desc):\n",
    "    out = desc.replace(\"ARG0: \", \"\")\n",
    "    out = out.replace(\"ARG1: \", \"\")\n",
    "    out = out.replace(\"V: \", \"\")\n",
    "    out = out.replace(\"[\", \"\")\n",
    "    out = out.replace(\"]\", \",\")\n",
    "    out = out.split(\",\")\n",
    "    out = list(map(lambda x: x.strip(), out))\n",
    "    out = list(map(lambda x: x.split(\" \"), out))\n",
    "    return out\n",
    "\n",
    "class PhrasalGenerator:\n",
    "    def __init__(self):\n",
    "        self.deptree = None\n",
    "        self.annotated = None\n",
    "        self.kb = {}\n",
    "        self.tree_log = []\n",
    "        self.sent_log = []\n",
    "        self.mod_at_left = [\n",
    "            \"advmod\", \"amod\", \"advmod:count\", \"acl:relcl\", \n",
    "            \"acl\", \"advcl\", \"xcomp\", \"ccomp\", \"appos\"]\n",
    "        self.mod_at_right = []\n",
    "        \n",
    "        '''\n",
    "            \"ccomp\": self.generate_ccomp,\n",
    "            \"compound\": self.generate_inherite,\n",
    "            \"compound:prt\": self.generate_inherite,\n",
    "            \"cop\": self.generate_inherite,\n",
    "            \n",
    "            \"expl\": self.generate_expl,\n",
    "            \"nmod\": self.generate_nmod,\n",
    "            \"nmod:npmod\": self.generate_nmod,\n",
    "            \"nmod:tmod\": self.generate_nmod,\n",
    "            \"nmod:poss\": self.generate_nmod_poss,\n",
    "            \n",
    "            \"nummod\": self.generate_nummod,\n",
    "            \"obl\": self.generate_obj,\n",
    "            \"obl:npmod\": self.generate_oblnpmod,\n",
    "            \"obl:tmod\": self.generate_inherite,\n",
    "        '''\n",
    "\n",
    "    def deptree_generate(self, tree, annotated, original):\n",
    "        self.tree_log = []\n",
    "        self.sent_log = []\n",
    "        self.deptree = tree\n",
    "        self.annotated = annotated\n",
    "        self.ie_pred = {}\n",
    "        verbs = ie_extractor.predict(original)['verbs']\n",
    "        for verb in verbs:\n",
    "            self.ie_pred[verb['verb']] = fix_info(verb['description'])        \n",
    "        self.generate(self.deptree)\n",
    "\n",
    "    def generate(self, tree):\n",
    "        if tree.val in self.mod_at_left:\n",
    "            self.left_modifier_generate(tree)\n",
    "        elif tree.val == \"conj\" and tree.mark == \"+\":\n",
    "            self.generate_conj(tree)\n",
    "        elif tree.left != \"N\":\n",
    "            self.generate_default(tree)\n",
    "\n",
    "    def delete_left_modifier(self, tree):\n",
    "        tree.val = tree.right.val\n",
    "        tree.mark = tree.right.mark\n",
    "        tree.npos = tree.right.npos\n",
    "        tree.id = tree.right.id\n",
    "        tree.left = tree.right.left\n",
    "        tree.right = tree.right.right\n",
    "\n",
    "    def rollback(self, tree, backup):\n",
    "        tree.val = backup.val\n",
    "        tree.left = deepcopy(backup.left)\n",
    "        tree.right = deepcopy(backup.right)\n",
    "        tree.mark = backup.mark\n",
    "        tree.npos = backup.npos\n",
    "        tree.id = backup.id\n",
    "\n",
    "    def left_modifier_generate(self, tree):\n",
    "        # adv + VB | VB + adv => VB\n",
    "        # amod + Noun => Noun\n",
    "        # Noun + relcl => Noun\n",
    "        left = tree.left\n",
    "        right = tree.right\n",
    "        backup = deepcopy(tree)\n",
    "\n",
    "        if right.mark == \"+\":\n",
    "            self.delete_left_modifier(tree)\n",
    "            self.save_tree(isTree=True)\n",
    "            self.rollback(tree, backup)   \n",
    "\n",
    "        self.generate(tree.left)\n",
    "        self.generate(tree.right) \n",
    "\n",
    "    def rollback_annotation(self, generated, original):\n",
    "        word_id = self.annotated[generated]\n",
    "        del self.annotated[generated]\n",
    "        self.annotated[original] = word_id\n",
    "\n",
    "    def generate_conj(self, tree):\n",
    "        backup = deepcopy(tree)\n",
    "        self.left_modifier_generate(tree)\n",
    "\n",
    "        tree.val = tree.left.right.val\n",
    "        tree.mark = tree.left.right.mark\n",
    "        tree.npos = tree.left.right.npos\n",
    "        tree.id = tree.left.right.id\n",
    "        tree.left = backup.left.right.left\n",
    "        tree.right = backup.left.right.right\n",
    "        self.save_tree(isTree=True)\n",
    "        self.rollback(tree, backup)\n",
    "\n",
    "    def add_modifier(self, tree, mod, head, direct=0):\n",
    "        if direct == 0:\n",
    "            generated = ' '. join([mod, head])\n",
    "        else:\n",
    "            generated = ' '. join([head, mod])\n",
    "        word_id = self.annotated[head]\n",
    "        del self.annotated[head]\n",
    "        self.annotated[generated] = word_id\n",
    "        self.save_tree(isTree=False)\n",
    "        self.rollback_annotation(generated, head)\n",
    "\n",
    "    def generate_default(self, tree):\n",
    "        left = tree.left\n",
    "        right = tree.right\n",
    "\n",
    "        if right.npos is not None:\n",
    "            if \"NN\" in right.npos and right.mark == \"-\":\n",
    "                for adj in self.kb[\"ADJ\"]:\n",
    "                    self.add_modifier(tree, adj, right.val)\n",
    "                for rel in self.kb[\"RCL\"]:\n",
    "                    self.add_modifier(tree, rel, right.val, 1)\n",
    "            elif \"VB\" in right.npos and right.mark == \"-\":\n",
    "                for adv in self.kb[\"ADV\"]:\n",
    "                    self.add_modifier(tree, adv, right.val)\n",
    "                    description = self.ie_pred[right.val]\n",
    "                    arg1 = description[2][-1]\n",
    "                    self.add_modifier(tree, adv, arg1, 1)\n",
    "\n",
    "        self.generate(left)\n",
    "        self.generate(right)  \n",
    "\n",
    "    def save_tree(self, isTree):\n",
    "        if isTree:\n",
    "            self.tree_log.append(deepcopy(self.deptree))\n",
    "        else:\n",
    "            self.sent_log.append(deepcopy(self.annotated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AStarSearch:\n",
    "    def __init__(self):    \n",
    "        self.closed_forward = set()                   \n",
    "        self.entailments = set()\n",
    "        self.contradictions = set()\n",
    "        self.hypothesis = \"\"\n",
    "        self.phrasalGenerator = PhrasalGenerator()\n",
    "        self.sbert = sentenceBERT\n",
    "\n",
    "    def generate_premises(self, start):\n",
    "        self.entailments.clear()\n",
    "        self.contradictions.clear()\n",
    "        pipeline = PolarizationPipeline(\n",
    "            [start], verbose=0, parser=\"stanza\")\n",
    "        pipeline.run_polarize_pipeline()\n",
    "        #print(\"\\nPolarization Complete\")\n",
    "\n",
    "        for annotation in pipeline.annotations:\n",
    "            #print(\"\\n====================================\")\n",
    "            #print(\"\\nInit Premise: \" + annotation['annotated'])\n",
    "            #polarized = annotation['polarized']\n",
    "            #btreeViz = Tree.fromstring(polarized.replace('[', '(').replace(']', ')'))\n",
    "            #jupyter_draw_nltk_tree(btreeViz) \n",
    "            self.phrasalGenerator.deptree_generate(\n",
    "                annotation['polarized_tree'], \n",
    "                annotation['word_dict'], \n",
    "                annotation['original'])\n",
    "            for gen_tree in self.phrasalGenerator.tree_log:\n",
    "                generated, queue, _, _ = btreeToList(\n",
    "                    gen_tree, len(annotation['original']), {}, 0)\n",
    "                annotated = list(queue.popkeys())\n",
    "                #print(\"\\nNext Premise: \" + ' '.join(annotated))\n",
    "            for gen_sent in self.phrasalGenerator.sent_log:\n",
    "                self.entailments.add(' '.join(gen_sent.popkeys()))\n",
    "                #print(\"\\nNext Premise: \" + ' '.join(gen_sent.popkeys()))\n",
    "\n",
    "    def word_similarity(self, s1, s2):\n",
    "        num_sim = 0\n",
    "        seq1 = s1.split(\" \")\n",
    "        for w in seq1:\n",
    "            if w in s2:\n",
    "                num_sim += 1\n",
    "        return num_sim / len(seq1)\n",
    "\n",
    "    def inference_sts(self, seqs1, seqs2):\n",
    "        embeddings1 = self.sbert.encode(seqs1, convert_to_tensor=True)\n",
    "        embeddings2 = self.sbert.encode(seqs2, convert_to_tensor=True)\n",
    "        cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "        for i in range(len(seqs1)):\n",
    "            cost1 = cosine_scores[i][i].data.cpu().numpy()\n",
    "            cost2 = self.word_similarity(seqs1[i], seqs2[i])\n",
    "            cost = cost1 * cost2\n",
    "            return cost\n",
    "\n",
    "    def generate_motion(self, start, opened):\n",
    "        self.generate_premises(start)\n",
    "        for premise in self.entailments:\n",
    "            if premise in self.closed_forward:\n",
    "                continue\n",
    "            cost = self.inference_sts([premise], [self.hypothesis])\n",
    "            if premise not in opened:\n",
    "                opened[premise] = 1 - cost\n",
    "            if (1-cost) < opened[premise]:\n",
    "                opened[premise] = 1-cost\n",
    "\n",
    "    def query(self, premises, hypothesis):\n",
    "        self.closed_forward.clear()\n",
    "        self.hypothesis = hypothesis.lower()\n",
    "\n",
    "        kb = {\"ADJ\": [\"beautiful\", \"red\", \"fragret\"], \n",
    "              \"ADV\": [\"ergently\", \"clearly\", \"neccesaraly\"],\n",
    "              \"RCL\": [\"which is beautiful\", \"which opens at night\"]}\n",
    "        self.phrasalGenerator.kb = kb\n",
    "\n",
    "        open_lists = pqdict({})\n",
    "        open_lists[premises] = 1 - self.inference_sts([premises], [hypothesis])\n",
    "\n",
    "        while open_lists:\n",
    "            optimal = open_lists.popitem()\n",
    "            print(\"\\nOptimal: \", optimal)\n",
    "            if optimal[1] < 9.0e-07:\n",
    "                self.closed_forward.add((self.hypothesis, 0.0000))\n",
    "                return True\n",
    "            self.generate_motion(optimal[0], open_lists)\n",
    "            self.closed_forward.add(optimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = AStarSearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.64it/s]\n",
      "Optimal:  ('no flowers need light', 0.19805026054382324)\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n",
      "Optimal:  ('no flowers need light ergently', 0.07331925630569458)\n",
      "\n",
      "\n",
      "Optimal:  ('no red flowers need light ergently', 2.384185791015625e-07)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 211
    }
   ],
   "source": [
    "search.query(\"no flowers need light\", \"no red flowers need light ergently\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{('no flowers need light', 0.19805026054382324),\n",
       " ('no flowers need light ergently', 0.07331925630569458),\n",
       " ('no red flowers need light ergently', 0.0)}"
      ]
     },
     "metadata": {},
     "execution_count": 212
    }
   ],
   "source": [
    "search.closed_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "94aab336a04f5c3925a1bec1af7c83ad27d94843d0f31b9ada3336f189da4289"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}